[["index.html", "Welcome Course Description Instructor Teaching Assistants Course Logistics Required Materials Learning Objectives Upon successful completion of this course, students will be able to: Tools Useful Links", " Welcome Welcome to the course website for The Science of Why: Causal Inference for Public Health. This course introduces the foundations of causal inference in public health and medical sciences, with an emphasis on distinguishing between association and causation in real-world research. Course Description In this course, students will: Explore foundational concepts such as counterfactuals, causal estimands, and identification strategies. Learn how to critically evaluate causal claims in public health literature. Understand and apply experimental and observational study designs, causal diagrams (DAGs), and bias adjustment methods. Develop practical skills through R-based tutorials and case studies. This course is ideal for undergraduates interested in public health, epidemiology, biostatistics, or social science research. Instructor Falco J. Bargagli-Stoffi Assistant Professor Department of Biostatistics UCLA Fielding School of Public Health falco@ucla.edu Office hours: By appointment. (Book via the scheduling link on this website.) Teaching Assistants TBD — will be announced on the course website. Course Logistics Offered: Fall Term Meetings: Lecture (3 hours), Discussion (1 hour) — in-person unless otherwise announced Assignments: Posted on the course website, due before 8 PM on specified dates Final Project: Group presentation + written report during finals week Required Materials Primary Textbook: Hernán MA, Robins JM. (2023) Causal Inference: What If Free PDF available here Secondary (Recommended) Texts: - Rosenbaum PR. Causal Inference. MIT Press. - Pearl J., Mackenzie D. The Book of Why. Basic Books. Supplementary Readings: Will be shared throughout the course. Learning Objectives Syllabus This course introduces students to the foundations of causal inference in public health and medical sciences, with a strong emphasis on the difference between association and causation. Students will learn to critically evaluate causal claims, understand causal diagrams (DAGs), and assess study design choices in both randomized and observational studies. We will explore how causal effects are identified and estimated, how to detect and adjust for biases (like confounding and selection bias), and how to use critical thinking tools when reviewing public health research. Students will also be introduced to concepts like effect modification, interaction, and systems thinking through real-world applications. Upon successful completion of this course, students will be able to: Communicate public health findings and causal claims in written and oral forms Evaluate causal claims in academic and public health literature Design and assess both randomized trials and observational studies Construct and analyze causal diagrams (DAGs) for identifying sources of bias Apply concepts of effect modification, interaction, and confounding Interpret findings within the context of public health policy and practice Work independently and collaboratively to assess causal research Tools This course will make use of: - R and RStudio - Interactive R tutorials and guided analysis - GitHub for accessing materials and submitting assignments Useful Links UCLA Center for Accessible Education UCLA Equity, Diversity, and Inclusion FSPH EDI Initiative "],["setup.html", "Setup Installing and Using Required Packages Loading Packages Difference Between install.packages() and library() Session Information Why include this? Base R version (simple)", " Setup Installing and Using Required Packages Throughout this tutorial, we’ll use a few essential R packages to manipulate data, run models, and create plots. Below are the core packages, what they do, and how to install them. Packages we’ll use: ggplot2 – For plotting (e.g., scatterplots, regression lines) dplyr – For data wrangling (filtering, mutating, summarizing, etc.) gridExtra – To combine multiple plots into one figure stats – Comes with base R and used for regression (lm()) pacman – Simplifies package management in R broom (optional) – Makes model summaries easier to work with # install.packages(c(&quot;ggplot2&quot;, &quot;dplyr&quot;, &quot;gridExtra&quot;, &quot;pacman&quot;, &quot;broom&quot;)) Loading Packages library(ggplot2) library(dplyr) ## ## Attaching package: &#39;dplyr&#39; ## The following objects are masked from &#39;package:stats&#39;: ## ## filter, lag ## The following objects are masked from &#39;package:base&#39;: ## ## intersect, setdiff, setequal, union library(gridExtra) ## ## Attaching package: &#39;gridExtra&#39; ## The following object is masked from &#39;package:dplyr&#39;: ## ## combine # Optional if using tidy model outputs: # library(broom) Difference Between install.packages() and library() install.packages(“dplyr”) downloads and installs the package — you only need to do this once per computer. library(dplyr) loads the package into your R session — you need to run this each time you use it. Session Information It’s always good practice to include your session info at the end of your analysis. This gives a snapshot of: Your R version and system details All the packages that were loaded The versions of those packages This is especially useful when: - You’re debugging errors - You’re submitting assignments - You’re collaborating with others Why include this? Sometimes code behaves differently depending on the version of a package or even the version of R itself. Including your session info makes your work reproducible and easier to troubleshoot. Base R version (simple) This function comes with R and gives you basic session details. sessionInfo() ## R version 4.5.1 (2025-06-13 ucrt) ## Platform: x86_64-w64-mingw32/x64 ## Running under: Windows 11 x64 (build 26100) ## ## Matrix products: default ## LAPACK version 3.12.1 ## ## locale: ## [1] LC_COLLATE=English_United States.utf8 ## [2] LC_CTYPE=English_United States.utf8 ## [3] LC_MONETARY=English_United States.utf8 ## [4] LC_NUMERIC=C ## [5] LC_TIME=English_United States.utf8 ## ## time zone: America/New_York ## tzcode source: internal ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods base ## ## other attached packages: ## [1] gridExtra_2.3 dplyr_1.1.4 ggplot2_3.5.2 ## ## loaded via a namespace (and not attached): ## [1] vctrs_0.6.5 cli_3.6.5 knitr_1.50 rlang_1.1.6 ## [5] xfun_0.52 generics_0.1.4 jsonlite_2.0.0 glue_1.8.0 ## [9] htmltools_0.5.8.1 sass_0.4.10 scales_1.4.0 rmarkdown_2.29 ## [13] grid_4.5.1 evaluate_1.0.4 jquerylib_0.1.4 tibble_3.3.0 ## [17] fastmap_1.2.0 yaml_2.3.10 lifecycle_1.0.4 bookdown_0.43 ## [21] compiler_4.5.1 RColorBrewer_1.1-3 pkgconfig_2.0.3 farver_2.1.2 ## [25] digest_0.6.37 R6_2.6.1 tidyselect_1.2.1 pillar_1.11.0 ## [29] magrittr_2.0.3 bslib_0.9.0 withr_3.0.2 tools_4.5.1 ## [33] gtable_0.3.6 cachem_1.1.0 "],["foundations-of-causal-thinking-in-public-health.html", "1 Foundations of Causal Thinking in Public Health Class materials Textbook reading Supplementary reading Topics covered 1.1 Association vs. Causation 1.2 Introduction to Counterfactuals and Potential Outcomes 1.3 Causal Estimands and Identification", " 1 Foundations of Causal Thinking in Public Health Class materials Slides: Module 1 Recording: Module 1, Part 1.1 Recording: Module 1, Part 2.1 Recording: Module 1, Part 2.2 Textbook reading Hernán &amp; Robins, Causal Inference: What If – Chapters 1–2 Supplementary reading Pearl, J. and Mackenzie, D. (2018) The Book of Why: The New Science of Cause and Effect. Basic Books. Selected public health news articles (provided on the course site). Topics covered Association vs. Causation Introduction to Counterfactuals and Potential Outcomes Causal Estimands and Identification Critical reading exercise: analyzing causal claims in public health news 1.1 Association vs. Causation Association refers to a statistical relationship where two variables move together, but one doesn’t necessarily cause the other. For instance, ice cream sales and drowning incidents both rise in the summer, not because one causes the other, but because they share a third factor: temperature. In contrast, causation implies a direct cause-and-effect relationship, where changing one variable leads to changes in another. Establishing causation requires rigorous methods, such as randomized controlled trials, to rule out confounding factors. Simpson’s Paradox occurs when a trend appears in separate groups but reverses when the data are combined. This paradox is driven by confounding variables—unaccounted factors that influence both the treatment and the outcome. It illustrates how aggregated data can be misleading and emphasizes the importance of analyzing relationships within subgroups to avoid drawing incorrect conclusions. To demonstrate this paradox, I simulated a study comparing two pneumonia treatments across 2,000 people Treatment A was mostly given to mild cases, while Treatment B was given to severe cases. When data were analyzed without considering severity, Treatment A seemed more effective. However, when stratified by severity, Treatment B consistently showed lower death rates in both mild and severe groups. This was visualized through two plots: one showing the misleading overall trend, and another stratified by severity revealing the true relationship. # library(ggplot2) # library(dplyr) set.seed(123) n &lt;- 2050 severity &lt;- rep(c(&quot;Mild&quot;, &quot;Severe&quot;), times = c(1450, 600)) treatment &lt;- c(rep(&quot;Treatment A&quot;, 1400), rep(&quot;Treatment B&quot;, 50), rep(&quot;Treatment A&quot;, 100), rep(&quot;Treatment B&quot;, 500)) outcome &lt;- c(rbinom(1400, 1, 0.15), # Mild + A (15% death rate) rbinom(50, 1, 0.10), # Mild + B (10% death rate) rbinom(100, 1, 0.30), # Severe + A (30% death rate) rbinom(500, 1, 0.20)) # Severe + B (20% death rate) df &lt;- data.frame( Severity = severity, Treatment = treatment, Outcome = outcome ) death_counts &lt;- tapply(df$Outcome, list(df$Severity, df$Treatment), sum) table_counts &lt;- table(df$Severity, df$Treatment) death_rates &lt;- round(death_counts / table_counts, 3) overall_a &lt;- sum(df$Outcome[df$Treatment == &quot;Treatment A&quot;]) / sum(df$Treatment == &quot;Treatment A&quot;) overall_b &lt;- sum(df$Outcome[df$Treatment == &quot;Treatment B&quot;]) / sum(df$Treatment == &quot;Treatment B&quot;) print(&quot;Death rates by severity and treatment:&quot;) ## [1] &quot;Death rates by severity and treatment:&quot; print(death_rates) ## Treatment A Treatment B ## Mild 0.136 0.120 ## Severe 0.380 0.204 cat(&quot;Overall death rate (Treatment A):&quot;, round(overall_a, 3), &quot;\\n&quot;) ## Overall death rate (Treatment A): 0.153 cat(&quot;Overall death rate (Treatment B):&quot;, round(overall_b, 3), &quot;\\n&quot;) ## Overall death rate (Treatment B): 0.196 overall_plot_data &lt;- data.frame( X_Pos = c(1, 2), Death_rate = c(overall_a, overall_b), Treatment = c(&quot;Treatment A&quot;, &quot;Treatment B&quot;) ) p1 &lt;- ggplot(overall_plot_data, aes(x = X_Pos, y = Death_rate, color = Treatment)) + geom_point(size = 5) + geom_line(aes(group = 1), color = &quot;black&quot;, linewidth = 1.2) + scale_x_continuous(breaks = c(1, 2), labels = c(&quot;Treatment A&quot;, &quot;Treatment B&quot;)) + scale_color_manual(values = c(&quot;Treatment A&quot; = &quot;red&quot;, &quot;Treatment B&quot; = &quot;blue&quot;)) + labs(title = &quot;Overall Trend (Simpson&#39;s Paradox)&quot;, x = &quot;&quot;, y = &quot;Risk of Death&quot;) + theme_minimal() + guides(color = &quot;none&quot;) print(p1) If we only compare the death rates between groups that received treatment A against groups that received treatment B, treatment A seems to be more effective at treating patients. group_means &lt;- df %&gt;% group_by(Severity, Treatment) %&gt;% summarize(Death_rate = mean(Outcome), .groups = &quot;drop&quot;) %&gt;% mutate(X_Pos = case_when( Severity == &quot;Mild&quot; &amp; Treatment == &quot;Treatment A&quot; ~ 1, Severity == &quot;Mild&quot; &amp; Treatment == &quot;Treatment B&quot; ~ 2, Severity == &quot;Severe&quot; &amp; Treatment == &quot;Treatment A&quot; ~ 3, Severity == &quot;Severe&quot; &amp; Treatment == &quot;Treatment B&quot; ~ 4 ), Group = paste(Severity, &quot;-&quot;, Treatment), Treatment_Color = Treatment ) p2 &lt;- ggplot(group_means, aes(x = X_Pos, y = Death_rate, color = Treatment_Color)) + geom_point(size = 5) + geom_line(aes(group = Severity), color = &quot;black&quot;, linewidth = 1.2) + scale_x_continuous( breaks = 1:4, labels = c(&quot;Mild - A&quot;, &quot;Mild - B&quot;, &quot;Severe - A&quot;, &quot;Severe - B&quot;) ) + scale_color_manual( values = c(&quot;Treatment A&quot; = &quot;red&quot;, &quot;Treatment B&quot; = &quot;blue&quot;), name = &quot;Treatment&quot; ) + labs(title = &quot;Risk by Severity (Mild vs. Severe)&quot;, y = &quot;Risk of Death&quot;, x = &quot;&quot;) + theme_minimal() print(p2) Only after stratifying by the severity of the case are we able to observe that treatment B is actually more effective than treatment A for both mild and severe pneumonia cases. 1.2 Introduction to Counterfactuals and Potential Outcomes At the heart of causal inference lies a simple yet powerful idea: counterfactuals — what would have happened if something else had occurred. However, we can never observe both outcomes for the same person. This is known as the Fundamental Problem of Causal Inference. We only observe the outcome under the condition that actually occurred — everything else is unobserved, or counterfactual. Building on the concept of counterfactuals, the Average Treatment Effect (ATE) provides a formal way to quantify the impact of a treatment or intervention across a population. Since we cannot observe both potential outcomes (treated and untreated) for the same individual, ATE instead compares the average outcome we would see if everyone received the treatment versus if no one did. Mathematically, it is the difference between the expected value of the potential outcome under treatment and the expected value under control. While individual causal effects remain unobservable, the ATE offers a population-level summary of the treatment’s impact — a cornerstone of policy evaluation, randomized experiments, and observational causal analysis. Counterfactuals can be represented using potential outcomes notation. Here is the basic notation: \\(Y\\;=\\;\\) the observed outcome \\(Y(0)\\;=\\;\\) the potential outcome under no treatment \\(Y(1)\\;=\\;\\) the potential outcome under treatment \\(W\\;=\\;\\) a binary variable that represents whether a unit was treated or not. If \\(W = 1\\), then the unit was treated. If \\(W = 0\\), then the unit was not treated. Notice that the observed outcome can be expressed in terms of potential outcomes: \\(Y = (W)Y(1) + (1-W)Y(0)\\). So \\(Y = Y(1)\\) if the unit was treated and \\(Y = Y(0)\\) if the unit was not treated. The previous equation is known as consistency. n &lt;- 2000 age &lt;- rnorm(n, mean = 50, sd = 10) bmi &lt;- rnorm(n, mean = 25, sd = 4) cholesterol &lt;- rnorm(n, mean = 200, sd = 30) treatment &lt;- rbinom(n, 1, plogis(0.05 * age + 0.01 * cholesterol - 2)) y_0 &lt;- 140 - 0.5 * age + 0.3 * bmi + 0.2 * cholesterol + rnorm(n, sd = 5) y_1 &lt;- y_0 - (40 + 1.0 * age - 0.3 * cholesterol) + rnorm(n, sd = 1.5) y &lt;- ifelse(treatment == 1, y_1, y_0) true_ate &lt;- mean(y_1 - y_0) cat(&quot;True ATE:&quot;, round(true_ate, 3), &quot;\\n&quot;) ## True ATE: -30.026 df &lt;- data.frame(age, bmi, cholesterol, treatment, y) naive_ate &lt;- mean(df$y[df$treatment == 1]) - mean(df$y[df$treatment == 0]) cat(&quot;Naive (unadjusted) ATE estimate:&quot;, round(naive_ate, 3), &quot;\\n&quot;) ## Naive (unadjusted) ATE estimate: -31.246 1.3 Causal Estimands and Identification Causal estimands are the quantities we aim to estimate to understand the effect of a treatment or intervention. The most common estimands include: Average Treatment Effect (ATE): Measures the average difference in outcomes if everyone received the treatment versus if no one did. \\[ ATE = E[Y(1)-Y(0)] \\] Average Treatment Effect on the Treated (ATT): Measures the effect of treatment for those who actually received the treatment. \\[ ATT = E[Y(1) - Y(0)\\ | \\ W = 1] \\] Average Treatment Effect on the Controls (ATC): Measures the effect for those who did not receive the treatment. \\[ ATC = E[Y(1) - Y(0)\\ | \\ W = 0] \\] Conditional Average Treatment Effect (CATE): Measures the treatment effect for subgroups defined by observed characteristics (e.g., older vs. younger patients). \\[ CATE = E[Y(1) - Y(0)\\ | \\ X = x] \\] Think of \\(X=x\\) where \\(X\\) is some form of age classification and \\(x\\) could be a value of the age classifcation, such as younger or older. Identification is the process of linking a causal estimand (like ATE) to observable data. Without valid identification, any estimates we produce may be biased or incorrect. One major challenge in causal inference is that we can never observe both potential outcomes for the same person — only the outcome under the actual treatment they received. This is the Fundamental Problem of Causal Inference. "],["randomized-control-trials.html", "2 Randomized Control Trials Class materials Textbook reading Supplementary reading Topics covered 2.1 Randomized controlled trials: the gold standard 2.2 Basic Experimental Design Principles 2.3 Limitations of RCTs in Public Health Contexts 2.4 Common Threats to Internal and External Validity", " 2 Randomized Control Trials Class materials Slides: Module 2 Recording: Module 2, Part 1 Recording: Module 2, Part 2 Textbook reading Hernán &amp; Robins, Causal Inference: What If – Chapters 3–4 Supplementary reading Pearl, J. (2009). Causal inference in statistics: An overview. Statistics Surveys, 3, 96–146.  Selected DAG examples from public health studies (provided in class) Topics covered Randomized controlled trials: the gold standard Basic experimental design principles Limitations of RCTs in public health contexts Common threats to internal and external validity Critical reading exercise: evaluating a published RCT 2.1 Randomized controlled trials: the gold standard Randomized Controlled Trials (RCTs) are widely considered the gold standard in causal inference because they offer the most rigorous way to establish whether a treatment or intervention truly causes an outcome. The key feature that sets RCTs apart is randomization: participants are randomly assigned to treatment or control groups, which ensures that—on average—all other characteristics (like age, health status, and behaviors) are equally distributed across groups. This process breaks any systematic link between confounders and treatment assignment, making the groups exchangeable and allowing us to interpret differences in outcomes as causal effects of the treatment. Because of this design, RCTs eliminate the need to adjust for confounders or worry about selection bias in the same way observational studies do. They provide clean estimates of the average treatment effect (ATE) with high internal validity, especially when they are well-executed and have minimal loss to follow-up. However, RCTs are not without limitations. They can be expensive, time-consuming, and sometimes unethical or impractical—such as when withholding treatment would cause harm. Despite these limitations, RCTs serve as the benchmark against which other study designs are compared, and understanding their strengths helps us interpret both experimental and non-experimental evidence more critically. In this simulation, I will recreate a simple randomized controlled trial (RCT) to estimate the effect of a new treatment on patient outcomes. I randomly assigned 2,000 individuals to either a treatment or control group and simulate their outcomes based on their assignment. Because of randomization, I expected the two groups to be similar in baseline characteristics, allowing for an unbiased estimate of the treatment effect. After simulating the data, I estimated the Average Treatment Effect (ATE) by comparing mean outcomes between the groups, and visualized the distribution of outcomes to confirm the treatment impact. I also show random assignment allows for the exchangeability assumption to hold. Simulated Baseline Data and Treatment Assignment pacman::p_load(&quot;dplyr&quot;, &quot;ggplot2&quot;) n &lt;- 2000 age &lt;- rnorm(n, 50, 10) treatment &lt;- rbinom(n, 1, 0.5) y_0 &lt;- 100 - 0.3 * age + rnorm(n, sd = 10) y_1 &lt;- y_0 - 10 + rnorm(n, sd = 5) y &lt;- ifelse(treatment == 1, y_1, y_0) rct_data &lt;- data.frame( age = age, treatment = treatment, y = y ) head(rct_data) ## age treatment y ## 1 70.65289 0 70.64327 ## 2 60.26631 0 84.00313 ## 3 56.38332 1 62.38144 ## 4 57.79955 1 55.04975 ## 5 36.34660 0 84.09071 ## 6 40.80364 1 49.72174 Estimated the Average Treatment Effect (ATE) ate_estimate &lt;- rct_data |&gt; group_by(treatment) |&gt; summarize(mean_outcome = mean(y)) |&gt; summarize(ATE = diff(mean_outcome)) |&gt; pull(ATE) paste(&quot;Estimated ATE: &quot;, round(ate_estimate, 2)) ## [1] &quot;Estimated ATE: -10.17&quot; Visualization of the Outcome Distributions ggplot(rct_data, aes(x = as.factor(treatment), y = y, fill = as.factor(treatment))) + geom_boxplot(alpha = 0.7) + labs( title = &quot;Distribution of Outcomes by Treatment Group&quot;, x = &quot;Treatment: Control (0) vs Treated (1)&quot;, y = &quot;Outcome&quot; ) + scale_fill_manual(values = c(&quot;red&quot;, &quot;blue&quot;)) + theme_minimal() Visualization of Observables ggplot(rct_data, aes(x = age, color = as.factor(treatment), fill = as.factor(treatment))) + geom_density(alpha = 0.4) + scale_fill_manual(values = c(&quot;0&quot; = &quot;red&quot;, &quot;1&quot; = &quot;blue&quot;), labels = c(&quot;Control&quot;, &quot;Treated&quot;), name = &quot;Group&quot;) + scale_color_manual(values = c(&quot;0&quot; = &quot;red&quot;, &quot;1&quot; = &quot;blue&quot;), labels = c(&quot;Control&quot;, &quot;Treated&quot;), name = &quot;Group&quot;) + labs(x = &quot;Age&quot;, y = &quot;Density&quot;, title = &quot;Density Plot for Treated and Control Groups&quot;) + theme_minimal() This plot shows that randomization balances on observable (and unobservable factors). We see that the distribution of age is balanced is pretty much identical between the treated and control groups. Since the treatment and control groups are practically the same, we say they are exchangeable. 2.2 Basic Experimental Design Principles At the heart of randomized controlled trials (RCTs) lies experimental design, the set of strategies we use to ensure that the comparison between groups is fair, unbiased, and informative. Good experimental design ensures that any differences in outcomes between the treatment and control groups can be confidently attributed to the treatment itself, and not to other confounding variables. Three basic principles guide experimental design: randomization, control, and replication. Randomization is the process of randomly assigning participants to treatment or control groups. This prevents systematic differences between groups at baseline and ensures that confounding variables (both known and unknown) are evenly distributed. Control involves creating a baseline group (the control group) that does not receive the treatment, allowing for a meaningful comparison. Replication refers to having enough participants so that random fluctuations even out, providing more precise and reliable estimates of the treatment effect. In our previous simulation, we applied these principles by randomly assigning 2,000 individuals to either a treatment or control group, simulating outcomes based only on treatment status and baseline characteristics (age). Because we randomized treatment assignment, we can be confident that any observed difference in outcomes is causally attributable to the treatment, not to age differences, baseline health, or other confounders. Without randomization, we would have needed to control for these factors. This simulation highlights why randomization is considered the gold standard for causal inference. 2.3 Limitations of RCTs in Public Health Contexts While randomized controlled trials (RCTs) are the gold standard for establishing causality, they are not without important limitations when applied to public health settings. First, ethical constraints often limit what interventions can be randomly assigned. For example, it would be unethical to randomly assign people to smoke or not smoke in order to study lung cancer. Public health research must often rely on observational studies where randomization is impossible. Second, feasibility and cost can be major barriers. Conducting large-scale RCTs can require enormous resources, making them impractical for studying widespread or long-term public health interventions like school nutrition programs or climate effects on health. Generalizability is another concern. Many RCTs are conducted in tightly controlled environments with selective populations, meaning their results may not apply to broader, more diverse real-world populations. In our earlier simulation, randomization guaranteed an unbiased estimate of the average treatment effect (ATE) within the study population. However, in real-world public health research, participants who volunteer for RCTs may differ from the general public, and interventions may behave differently outside of controlled settings. This highlights the importance of thinking critically about how experimental results translate into everyday public health practice. 2.4 Common Threats to Internal and External Validity When evaluating any causal study, it’s critical to think about validity, whether the results are accurate (internal validity) and whether they generalize beyond the study setting (external validity). Internal validity refers to whether the observed effect truly reflects the causal effect within the study population. Threats to internal validity include: Confounding, if randomization fails or is compromised (e.g., noncompliance with assigned treatment). Selection bias, if participants drop out or are lost to follow-up in a way that is related to both treatment and outcome. Measurement error, if outcomes or treatments are recorded inaccurately. External validity, on the other hand, concerns whether results from the study can be generalized to other settings, populations, or time periods. Threats to external validity include: Non-representative samples, such as RCTs recruiting only highly motivated individuals who differ from the general population. Intervention differences, where the way a treatment is delivered in a trial setting doesn’t match how it would be implemented in the real world. Contextual factors, such as cultural, economic, or healthcare system differences that make the same intervention work differently elsewhere. In the earlier RCT simulation, we achieved excellent internal validity because treatment was randomized perfectly and outcomes were cleanly measured. However, that simulation assumes an idealized setting; in real public health research, threats to validity often creep in, and careful design and critical thinking are needed to recognize and minimize them. "],["observational-studies.html", "3 Observational Studies Class materials Textbook reading Supplementary reading Topics covered 3.1 The challenge of confounding in public health and medical research 3.2 Exchangeability, positivity, and consistency 3.3 Effect Identification in Observational Studies", " 3 Observational Studies Class materials Slides: Module 3 Recording: Module 3, Part 1 Recording: Module 3, Part 2 Textbook reading Hernán &amp; Robins, Causal Inference: What If – Chapters 5–6 Supplementary reading Greenland, S. (2003). Quantifying biases in causal models: classical confounding vs collider-stratification bias. Epidemiology, 14(3), 300–306.  Additional DAG exercises provided in class Topics covered The challenge of confounding in public health and medical research Exchangeability, positivity, and consistency Effect identification in observational studies Critical reading exercise: evaluating a published observational study 3.1 The challenge of confounding in public health and medical research Confounding is a major challenge in public health and medical research because it can create misleading associations between exposures and outcomes. A confounder is a third variable that is associated with both the exposure and the outcome, potentially distorting the true causal relationship. For example, if we observe that people who carry lighters tend to have higher rates of lung cancer, we might wrongly conclude that carrying a lighter causes cancer. In reality, smoking is the confounding variable: smokers are more likely to carry lighters and also more likely to develop lung cancer. Without properly adjusting for confounders, studies risk producing biased estimates, leading to incorrect conclusions about risk factors, treatments, or interventions. Addressing confounding is crucial but not always straightforward. Methods such as stratification, multivariable regression, propensity score matching, and randomized controlled trials (RCTs) are commonly used to try to adjust for or eliminate confounding effects. However, identifying all relevant confounders can be difficult, especially when dealing with observational data where randomization is not possible. Unmeasured or unknown confounders remain a constant threat to validity. Therefore, careful study design, domain knowledge, and sensitivity analyses are essential to minimize the impact of confounding and ensure more reliable and actionable public health research findings. Example Setup Let’s say we want to study the effect of Exercise (X) on Heart Health (Y), but there’s a Genetic Factor (Z) that causes both Exercise and Heart Health. In this case, Z is a confounder, and we should adjust for it. n &lt;- 2000 genetics &lt;- rnorm(n) exercise &lt;- 0.6 * genetics + rnorm(n) heart_health &lt;- 0.8 * exercise + 0.5 * genetics + rnorm(n) df &lt;- data.frame(heart_health, exercise, genetics) model_naive &lt;- lm(heart_health ~ exercise, data = df) summary(model_naive)$coefficients[&quot;exercise&quot;, ] ## Estimate Std. Error t value Pr(&gt;|t|) ## 0.99441785 0.02092428 47.52458309 0.00000000 model_adjusted &lt;- lm(heart_health ~ exercise + genetics, data = df) summary(model_adjusted)$coefficients[&quot;exercise&quot;, ] ## Estimate Std. Error t value Pr(&gt;|t|) ## 7.850907e-01 2.257521e-02 3.477667e+01 1.347795e-207 # library(ggplot2) naive_estimate &lt;- summary(model_naive)$coefficients[&quot;exercise&quot;, &quot;Estimate&quot;] adjusted_estimate &lt;- summary(model_adjusted)$coefficients[&quot;exercise&quot;, &quot;Estimate&quot;] estimates &lt;- data.frame( Model = c(&quot;Naive&quot;, &quot;Adjusted&quot;), Estimate = c(naive_estimate, adjusted_estimate) ) ggplot(estimates, aes(x = Model, y = Estimate, fill = Model)) + geom_col(width = 0.5) + labs(title = &quot;Comparison of Naive vs Adjusted Estimates&quot;, y = &quot;Estimated Effect of Exercise&quot;, x = &quot;&quot;) + theme_minimal() + theme(legend.position = &quot;none&quot;) In this simulation, we model a situation where Genetics (Z) is a confounder that influences both Exercise (X) and Heart Health (Y). The naive model, which regresses Heart Health on Exercise without adjusting for Genetics, gives a biased estimate of the effect of Exercise. This happens because part of the observed association is actually due to Genetics, not Exercise itself. When we adjust for Genetics in the second model, the estimate of Exercise’s effect becomes more accurate, isolating its true relationship with Heart Health. This example highlights how failing to account for confounding can lead researchers to overstate or misinterpret causal effects in public health and medical studies. 3.2 Exchangeability, positivity, and consistency In causal inference, particularly when analyzing observational data, three critical assumptions must hold for estimates to reflect true causal relationships: exchangeability, positivity, and consistency. These assumptions ensure that the comparisons we make between groups are valid and that the effects we estimate correspond to real-world interventions. Without them, causal conclusions can be biased or entirely invalid. Exchangeability means that after adjusting for confounders, the treatment and comparison groups are similar in all relevant ways except for the exposure itself. Positivity means that every individual has a nonzero probability of receiving each level of the exposure, regardless of their confounder values. Consistency means that the observed outcome under the actual exposure is the same as the potential outcome we are trying to measure for that exposure level. In our previous simulation studying exercise and heart health, adjusting for genetics aimed to restore exchangeability by balancing genetic differences between individuals with different exercise levels. Positivity was satisfied because individuals at all levels of genetics still varied in how much they exercised. Consistency was assumed because the way we measured exercise and heart health accurately reflected the underlying causal relationship. Together, these assumptions allowed us to interpret the adjusted effect of exercise on heart health as a causal effect. 3.3 Effect Identification in Observational Studies In observational studies, identifying causal effects is challenging because researchers do not control exposure assignments. Unlike randomized controlled trials, individuals self-select into exposure groups, leading to potential confounding. Effect identification requires careful strategies to mimic the conditions of randomization and ensure that observed associations reflect true causal relationships rather than biases from confounding or selection. Confounding control: Adjust for confounders through methods like regression, stratification, matching, or weighting to approximate randomization. Assumptions: Rely on assumptions like exchangeability, positivity, and consistency to justify causal interpretation. Sensitivity analysis: Explore how robust the estimated effect is to potential unmeasured confounding. In our simulation of exercise and heart health, we identified the causal effect of exercise by adjusting for the confounding effect of genetics. Without randomization, genetics could have biased the relationship between exercise and health outcomes. By including genetics as a covariate in our model, we attempted to recreate the conditions needed for causal identification in an observational setting, relying on the assumptions of exchangeability, positivity, and consistency to interpret the adjusted exercise effect as causal. "],["effect-modification-and-interaction.html", "4 Effect Modification and Interaction Class materials Textbook reading Supplementary reading Topics covered 4.1 Effect Modification and Adjustment Methods 4.2 Identifying Interaction 4.3 Effect Modification vs Interaction", " 4 Effect Modification and Interaction Class materials Slides: Module 4 Recording: Module 4, Part 1 Recording: Module 4, Part 2 Textbook reading Hernán &amp; Robins, Causal Inference: What If – Chapters 7–8 Supplementary reading Freedman, D. A. (2008). On types of scientific inquiry: The role of RCTs in health policy. Journal of the Royal Statistical Society: Series A, 171(2), 359–385.  Examples of quasi-experiments from public health and education Topics covered Effect modification and adjustment methods Identifying interaction Effect modification vs interaction Critical reading exercise: evaluating effect modification and interaction in studies 4.1 Effect Modification and Adjustment Methods Effect modification occurs when the effect of an exposure on an outcome differs depending on the level of another variable. Unlike confounding, which biases the estimated effect, effect modification reflects a real variation in the causal effect across different subgroups. Recognizing effect modification is important because it can reveal that a treatment or exposure is beneficial for some groups but not for others. Adjustment methods like stratification or including interaction terms in regression models help detect and describe effect modification rather than “control” it away. Adjustment methods typically aim to control for confounding, but they can also be used to detect effect modification when interaction terms are included. When effect modification is present, a single summary effect estimate (like an overall average) can be misleading. Instead, researchers often report subgroup-specific effects. Careful modeling and interpretation are necessary to distinguish between true effect modification and residual confounding. Simulation to Demonstrate Effect Modification We simulate a case where heart transplant improves survival, but the effect of transplant is stronger for individuals who receive vitamin supplements. That is, vitamin supplementation modifies the effect of transplant on survival. This reflects a scenario where a treatment (transplant) has a greater benefit under certain conditions (when the body is supported by vitamins), illustrating effect modification. n &lt;- 2000 A &lt;- rbinom(n, 1, 0.5) # heart transplant E &lt;- rbinom(n, 1, 0.5) # vitamin survival &lt;- 1 * A + 2 * E + 3 * (A * E) + rnorm(n, mean = 0, sd = 1) df &lt;- data.frame(survival, A, E) naive_model &lt;- lm(survival ~ A + E, data = df) adjusted_model &lt;- lm(survival ~ A + E + A * E, data = df) summary(naive_model) ## ## Call: ## lm(formula = survival ~ A + E, data = df) ## ## Residuals: ## Min 1Q Median 3Q Max ## -3.6443 -0.9234 0.0055 0.9003 3.5857 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -0.73506 0.04938 -14.89 &lt;2e-16 *** ## A 2.50832 0.05729 43.78 &lt;2e-16 *** ## E 3.47181 0.05728 60.61 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1.281 on 1997 degrees of freedom ## Multiple R-squared: 0.7361, Adjusted R-squared: 0.7358 ## F-statistic: 2785 on 2 and 1997 DF, p-value: &lt; 2.2e-16 summary(adjusted_model) ## ## Call: ## lm(formula = survival ~ A + E + A * E, data = df) ## ## Residuals: ## Min 1Q Median 3Q Max ## -3.5538 -0.6745 -0.0114 0.7051 2.8409 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 0.05652 0.04432 1.275 0.202 ## A 0.90599 0.06305 14.369 &lt;2e-16 *** ## E 1.89178 0.06261 30.215 &lt;2e-16 *** ## A:E 3.21151 0.08926 35.978 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.9979 on 1996 degrees of freedom ## Multiple R-squared: 0.8399, Adjusted R-squared: 0.8396 ## F-statistic: 3490 on 3 and 1996 DF, p-value: &lt; 2.2e-16 The plot shows that heart transplants improve survival more for individuals who received vitamins, illustrating effect modification by vitamin status. # library(ggplot2) # library(dplyr) df_grouped &lt;- df |&gt; mutate(vitamin_group = ifelse(E == 1, &quot;Vitamins&quot;, &quot;No Vitamins&quot;)) ggplot(df_grouped, aes(x = A, y = survival, color = vitamin_group)) + geom_jitter(width = 0.1, alpha = 0.4) + stat_summary(fun = mean, geom = &quot;point&quot;, size = 3, shape = 18) + stat_summary(fun = mean, geom = &quot;line&quot;, aes(group = vitamin_group)) + scale_x_continuous(breaks = c(0, 1)) + labs(title = &quot;Effect Modification: Heart Transplant × Vitamin Supplement&quot;, x = &quot;Heart Transplant (A)&quot;, y = &quot;Survival&quot;, color = &quot;Vitamin Group&quot;) + theme_minimal() In this simulation, the benefit of heart transplant on survival is stronger for individuals who received vitamin supplements. A naive model without an interaction term fails to capture this difference and instead estimates an average effect across all individuals. By including an interaction term between transplant and vitamins, we reveal that the effect of transplant varies depending on vitamin use. The plot illustrates how survival is influenced not just by transplant alone, but by how vitamins modify its impact — highlighting the importance of detecting and modeling effect modification in public health research. 4.2 Identifying Interaction Identifying interaction is crucial when studying causal relationships because it tells us whether the effect of an exposure on an outcome varies across levels of another variable. An interaction exists when the impact of one variable depends on the value of another, meaning the combined effect is not simply additive. Rather than being a source of bias like confounding, interaction reveals real differences in how subgroups respond to exposures or treatments. Detecting interaction helps researchers understand for whom and under what conditions an intervention works best, allowing for more tailored public health strategies and clinical recommendations. In our simulation with heart transplant and vitamin supplements, interaction was present because the benefit of transplant on survival was greater for individuals who received vitamins. By fitting a model with an interaction term between transplant and vitamin use, we were able to identify and quantify this effect modification. Without testing for interaction, we would have incorrectly assumed that transplant provides the same benefit to everyone, masking important subgroup differences. Identifying interaction allows us to uncover nuanced causal relationships that average treatment effects alone may overlook. 4.3 Effect Modification vs Interaction Effect modification and interaction are closely related concepts, but they serve slightly different purposes in causal analysis. Effect modification refers to a real difference in the causal effect of an exposure on an outcome across levels of another variable. It describes a biological or contextual phenomenon where an exposure has varying impacts depending on a modifier, such as a treatment working better for younger patients than older ones. In contrast, interaction is a modeling term: it refers to the inclusion of a product term (like exposure × modifier) in a statistical model to detect and estimate effect modification. In essence, effect modification is a feature of reality, while interaction is how we model and identify it in data. In our simulation with heart transplant and vitamin supplements, the true underlying process involved effect modification: the benefit of transplant on survival was greater for individuals who received vitamins. To uncover this, we included an interaction term between transplant and vitamin use (A * E) in our regression model. Without this interaction, the model would have incorrectly assumed a constant effect of transplant across all patients, regardless of vitamin status. This distinction underscores the importance of modeling interactions when effect modification is suspected — otherwise, meaningful subgroup differences in treatment effects can be obscured by oversimplified models. "],["introduction-to-causal-diagrams.html", "5 Introduction to Causal Diagrams Class materials Textbook reading Supplementary reading Topics covered 5.1 Basic principles of directed acyclic graphs (DAGs) 5.2 Common Causal Structures in Public Health 5.3 Using DAGs to introduce and understand selection bias", " 5 Introduction to Causal Diagrams Class materials Slides: Module 5 Recording: Module 5, Part 1 Recording: Module 5, Part 2 Textbook reading Hernán &amp; Robins, Causal Inference: What If – Chapters 9–10 Supplementary reading Rosenbaum, P.R., &amp; Rubin, D.B. (1983). The central role of the propensity score in observational studies for causal effects. Biometrika, 70(1), 41–55. Examples from public health studies involving confounding adjustment Topics covered Basic principles of directed acyclic graphs (DAGs) Common causal structures in public health Using DAGs to introduce and understand selection bias Application: drawing DAGs for public health scenarios 5.1 Basic principles of directed acyclic graphs (DAGs) Directed acyclic graphs (DAGs) are powerful tools in causal inference that visually represent assumptions about how variables are related. In a DAG, nodes represent variables, and arrows (directed edges) represent causal influences from one variable to another. DAGs are acyclic, meaning you cannot return to the same variable by following a sequence of arrows — this prevents feedback loops. The key strength of DAGs lies in their ability to clarify causal pathways, distinguish between confounding and mediation, and identify the variables we need to control for to estimate causal effects accurately. By encoding assumptions explicitly, DAGs help researchers determine whether observed associations reflect true causal relationships or are biased by omitted variables or incorrect conditioning. In our simulation, we use a DAG to represent a common public health structure involving diet, exercise, and heart health. Diet is a confounder: it directly influences both how much people exercise and their overall heart health. If we ignore diet when estimating the effect of exercise on heart health, we risk attributing diet’s effect to exercise — leading to confounding bias. The DAG for this scenario includes arrows from diet to both exercise and heart health, and from exercise to heart health. We also introduce selection bias by conditioning on individuals with moderate-to-high exercise levels. In DAG terms, this is equivalent to conditioning on a collider (exercise), which can open a non-causal backdoor path and bias our results. Modeling this setup with a DAG allows us to see clearly that to obtain an unbiased estimate of the causal effect of exercise, we must adjust for diet and avoid conditioning on colliders like selection into the sample. library(ggplot2) library(dplyr) library(ggdag) ## ## Attaching package: &#39;ggdag&#39; ## The following object is masked from &#39;package:stats&#39;: ## ## filter library(dagitty) n &lt;- 2000 diet &lt;- rnorm(n) exercise &lt;- 2 * diet + rnorm(n) heart_health &lt;- 3 * exercise + 4 * diet + rnorm(n) dag &lt;- dagitty(&quot;dag { diet -&gt; exercise diet -&gt; heart_health exercise -&gt; heart_health }&quot;) plot(dag) ## Plot coordinates for graph not supplied! Generating coordinates, see ?coordinates for how to set your own. adjustmentSets(dag, exposure = &quot;exercise&quot;, outcome = &quot;heart_health&quot;) ## { diet } New Simulation library(bnlearn) ## ## Attaching package: &#39;bnlearn&#39; ## The following objects are masked from &#39;package:dagitty&#39;: ## ## ancestors, children, descendants, parents, spouses library(igraph) ## ## Attaching package: &#39;igraph&#39; ## The following objects are masked from &#39;package:bnlearn&#39;: ## ## as.igraph, compare, degree, subgraph ## The following object is masked from &#39;package:dagitty&#39;: ## ## edges ## The following objects are masked from &#39;package:dplyr&#39;: ## ## as_data_frame, groups, union ## The following objects are masked from &#39;package:stats&#39;: ## ## decompose, spectrum ## The following object is masked from &#39;package:base&#39;: ## ## union n &lt;- 2000 diet &lt;- rnorm(n) exercise &lt;- 2 * diet + rnorm(n) heart_health &lt;- 3 * exercise + 4 * diet + rnorm(n) df &lt;- data.frame(diet, exercise, heart_health) dag_learned &lt;- hc(df) dag_igraph &lt;- as.igraph(dag_learned) plot( dag_igraph, vertex.label.color = &quot;black&quot;, vertex.size = 30, edge.arrow.size = 0.5, layout = layout_as_tree(dag_igraph) ) 5.2 Common Causal Structures in Public Health In public health research, understanding the causal relationships between variables is essential for identifying risk factors, designing interventions, and making policy decisions. Common causal structures include confounding, mediation, and collider bias, each of which influences how we interpret observed associations. A confounder is a variable that affects both the exposure and the outcome, potentially biasing the estimated effect if not properly adjusted for. A mediator lies on the causal pathway between exposure and outcome, helping to explain how the exposure exerts its effect. A collider, on the other hand, is influenced by two variables, and conditioning on it can introduce spurious associations. Identifying these structures often requires drawing directed acyclic graphs (DAGs) to map out assumptions and determine which variables to adjust for when estimating causal effects. In our simulation, we modeled a classic confounding structure, where diet influences both exercise and heart health. This mirrors real-world public health situations where health behaviors and biological outcomes are shaped by shared underlying factors like nutrition, socioeconomic status, or genetics. If we were to estimate the effect of exercise on heart health without adjusting for diet, we would risk attributing some of diet’s impact to exercise — a classic confounding problem. By visualizing the relationships using a DAG and including diet as a covariate in our regression model, we can block the backdoor path and isolate the true causal effect of exercise. This illustrates how understanding and modeling common causal structures is critical to producing valid and meaningful results in public health research. 5.3 Using DAGs to introduce and understand selection bias Selection bias occurs when the group of individuals included in a study is systematically different from the target population in a way that distorts the relationship between exposure and outcome. This can happen when inclusion into the study depends on variables that are related to either the exposure, the outcome, or both. Selection bias becomes especially problematic when researchers condition on a collider — a variable that is influenced by two or more variables in the causal model — because doing so can open non-causal paths and create spurious associations. In practical terms, this means that even if there is no causal relationship between an exposure and an outcome, conditioning on a collider can make it look like there is one, or it can distort the strength of a real effect. In our simulation, we introduced selection bias by only including individuals with moderate to high diet scores. Since diet is a confounder that affects both exercise and heart health, restricting our analysis to individuals with good diets creates a biased sample — one that no longer reflects the full population variation in diet. This conditioning on diet essentially blocks our ability to observe the full confounding relationship and can make the estimated effect of exercise on heart health appear stronger, weaker, or even reverse. By simulating this, we demonstrate how selection bias — even when introduced through something seemingly harmless like focusing on healthier individuals — can lead to incorrect causal conclusions if not properly accounted for. df &lt;- data.frame(diet, exercise, heart_health) df_selected &lt;- df |&gt; filter(diet &gt; 0) model_naive &lt;- lm(heart_health ~ exercise, data = df_selected) model_adjusted &lt;- lm(heart_health ~ exercise + diet, data = df_selected) summary(model_naive)$coefficients[&quot;exercise&quot;, ] ## Estimate Std. Error t value Pr(&gt;|t|) ## 4.14344585 0.03776859 109.70614088 0.00000000 summary(model_adjusted)$coefficients[&quot;exercise&quot;, ] ## Estimate Std. Error t value Pr(&gt;|t|) ## 3.01503260 0.03231176 93.31068101 0.00000000 selection_bias_dag &lt;- dagitty(&quot;dag { diet -&gt; exercise diet -&gt; heart_health exercise -&gt; heart_health diet -&gt; selection }&quot;) plot(selection_bias_dag) ## Plot coordinates for graph not supplied! Generating coordinates, see ?coordinates for how to set your own. "],["confounding-and-selection-bias.html", "6 Confounding and Selection Bias Class materials Textbook reading Supplementary reading Topics Covered 6.1 The Structure of Confounding 6.2 How to Adjust for Confounding 6.3 The Form of Selection Bias 6.4 How to Adjust for Selection Bias", " 6 Confounding and Selection Bias Class materials Slides: Module 6 Recording: Module 6, Part 1 Recording: Module 6, Part 2 Textbook reading Hernán &amp; Robins, Causal Inference: What If – Chapter 11 Supplementary reading Knol, M. J., &amp; VanderWeele, T. J. (2012). Recommendations for presenting analyses of effect modification and interaction. International Journal of Epidemiology, 41(2), 514–520. Real-world public health examples of effect modification Topics Covered The structure of confounding How to adjust for confounding The form of selection bias How to adjust for selection bias Critical reading exercise: sources of confounding and selection bias in public health 6.1 The Structure of Confounding Confounding occurs when an external variable influences both the exposure and the outcome, making it difficult to determine whether the observed association is truly causal. This third variable — the confounder — can create a misleading impression that the exposure causes the outcome, when in fact, the association may be driven entirely or partially by the confounder. The key structural feature of confounding is that the confounder must be related to both the exposure and the outcome. To obtain an accurate estimate of the exposure’s causal effect, researchers must adjust for confounding variables using methods like stratification, regression, or matching. In our simulation, age acts as a confounder because it affects both smoking behavior and lung cancer risk. Older individuals are more likely to smoke and also more likely to develop lung cancer, which can make smoking appear more harmful (or even less harmful) than it actually is if age isn’t taken into account. The naive model, which includes only smoking, produces a biased estimate because it doesn’t separate the effect of smoking from the effect of age. The adjusted model includes both smoking and age and provides a more accurate estimate of smoking’s effect by accounting for this confounding influence. This example highlights how confounding can distort findings and why controlling for related background variables is essential in observational research. n &lt;- 2000 age &lt;- rnorm(2000, mean = 50, sd = 10) smoking &lt;- 2 * age + rnorm(n) lung_cancer &lt;- 3 * smoking + 4 * age + rnorm(n) genetic_marker &lt;- rbinom(n, 1, prob = plogis(0.01 * smoking - 1)) df &lt;- data.frame( Age = age, Smoking = smoking, Lung_Cancer = lung_cancer, Genetic_Marker = genetic_marker ) model_naive &lt;- lm(lung_cancer ~ smoking, data = df) model_adjusted &lt;- lm(lung_cancer ~ smoking + age, data = df) coef_naive &lt;- summary(model_naive)$coefficients[&quot;smoking&quot;, &quot;Estimate&quot;] coef_adjusted &lt;- summary(model_adjusted)$coefficients[&quot;smoking&quot;, &quot;Estimate&quot;] coef_naive ## [1] 4.998041 coef_adjusted ## [1] 2.97812 6.2 How to Adjust for Confounding Adjusting for confounding is essential when estimating causal effects from observational data. Since confounders are variables that influence both the exposure and the outcome, failing to account for them can lead to biased and misleading conclusions. One of the most common ways to adjust for confounders is through multiple regression, where confounders are included as covariates in the model. Other methods include stratification, where analyses are performed within levels of the confounder, and matching, where exposed and unexposed individuals are paired based on similar values of the confounding variable. These approaches aim to isolate the effect of the exposure by holding confounders constant, thereby mimicking the balance achieved in randomized experiments. In our simulation, we demonstrated adjustment for confounding using regression. The variable age was a confounder because it influenced both smoking and lung cancer. When we fit a naive model that only included smoking, the effect estimate was biased because it reflected both smoking’s and age’s contributions to lung cancer. By including age in the model as an additional predictor, we were able to adjust for its influence. This adjustment allowed us to estimate the effect of smoking on lung cancer more accurately, as if age were held constant. This simple regression approach illustrates a key principle in observational research: if you can measure the confounder and include it in your analysis, you can often remove its biasing effect and get closer to the true causal relationship. 6.3 The Form of Selection Bias Selection bias arises when the individuals included in a study are not representative of the target population due to a systematic filtering process. This filtering — whether intentional (like restricting analysis to a subgroup) or unintentional (like only including those who responded to a survey) — can distort the observed relationship between an exposure and an outcome. The core structure of selection bias involves inclusion in the study being related to variables that are also related to the exposure or the outcome. This means the analysis is performed on a biased subset of the population, which can create spurious associations or mask real ones, even when a true causal effect exists. In our simulation, we introduced selection bias by restricting the dataset to individuals with moderate to good diets. Because diet is related to both exercise and heart health, this restriction caused the analyzed sample to no longer reflect the full population. As a result, the apparent relationship between exercise and heart health in the filtered sample may differ from the true relationship in the full population. This demonstrates the form of selection bias: by conditioning on a variable that is related to both the exposure and the outcome (in this case, indirectly through diet), we introduced distortion into the analysis. This example shows how selection criteria — even seemingly benign ones — can alter causal interpretations if they create unbalanced or artificially restricted datasets. df_biased &lt;- df |&gt; filter(genetic_marker == 1) model_naive &lt;- lm(lung_cancer ~ smoking, data = df_biased) model_adjusted &lt;- lm(lung_cancer ~ smoking + age, data = df_biased) coef_naive &lt;- summary(model_naive)$coefficients[&quot;smoking&quot;, &quot;Estimate&quot;] coef_adjusted &lt;- summary(model_adjusted)$coefficients[&quot;smoking&quot;, &quot;Estimate&quot;] coef_naive ## [1] 4.998041 coef_adjusted ## [1] 2.97812 6.4 How to Adjust for Selection Bias Adjusting for selection bias is more challenging than adjusting for confounding, because selection bias arises when the sample being analyzed is not representative of the target population due to a systematic inclusion process. This often happens when selection into the dataset depends on variables related to both the exposure and the outcome, introducing a spurious association that distorts causal estimates. Unlike confounding, which can often be handled by conditioning on measured variables, selection bias may require more complex strategies such as inverse probability weighting (IPW), sensitivity analysis, or explicitly modeling the selection mechanism. The key to adjusting for selection bias is understanding why and how certain individuals are excluded or included in the analysis — and then incorporating that information to correct the bias. In the simulation above, we introduced selection bias by filtering the dataset to include only individuals who smoked more than the average level. Because smoking is influenced by age and also affects lung cancer, conditioning on it distorts the relationship between age and lung cancer. While the naive model estimated the effect of smoking without accounting for age, the adjusted model included age as a covariate and produced a more accurate effect estimate. However, unlike confounding, adjusting for a covariate like age doesn’t always fully correct for selection bias — especially when selection is based on a collider or a downstream consequence of both exposure and outcome. This illustrates that although standard regression adjustment can help, it may not completely remove bias introduced through selective inclusion, reinforcing the need to carefully consider how and why individuals are included in an analysis. "],["other-common-pitfalls-of-causal-analyses.html", "7 Other Common Pitfalls of Causal Analyses Class materials Textbook reading Supplementary reading Topics covered 7.1 Measurement Bias 7.2 Non-Causal Diagrams 7.3 Publication Bias and P-Hacking 7.4 Over- and Mis-Interpretation of Statistical Analyses", " 7 Other Common Pitfalls of Causal Analyses Class materials Slides: Module 7 Recording: Module 7, Part 1 Recording: Module 7, Part 2 Textbook reading Hernán &amp; Robins, Causal Inference: What If – Chapters 12–13 Supplementary reading Groenwold, R. H., et al. (2012). Dealing with missing outcome data in randomized trials and observational studies. American Journal of Epidemiology, 175(3), 210–217. Examples of misclassification and selection bias in public health research Topics covered Measurement bias Non-causal diagrams Publication bias and p-hacking Over- and mis-interpretation of statistical analyses Application: developing a checklist for critical reading of causal claims 7.1 Measurement Bias Measurement bias occurs when the method used to collect data leads to systematic errors in the values recorded for a variable. This can happen when an exposure, outcome, or confounder is misclassified or inaccurately measured in a way that consistently overstates or understates the true value. Measurement bias is problematic because it can distort observed associations and lead to incorrect conclusions about the relationships between variables. Unlike random measurement error, which tends to cancel out over large samples, measurement bias introduces consistent errors that don’t disappear with more data. It can arise from faulty instruments, poorly worded survey questions, or inconsistent data collection procedures, and it often goes unnoticed unless explicitly tested for. In public health and medical research, measurement bias can affect both exposure and outcome variables. For example, if smoking behavior is self-reported and individuals tend to underreport how much they smoke, the study will underestimate the true relationship between smoking and lung cancer. Similarly, if age is recorded in broad categories rather than precise years, it can limit the ability to adjust accurately for confounding. Even adjusting for confounders may not correct measurement bias if those confounders are also measured with error. This makes it critical to use reliable, validated measurement tools and to account for potential misclassification during analysis, especially in observational studies where data quality may vary widely. This simulation demonstrates measurement bias by comparing the estimated effect of smoking on lung cancer using the true smoking values versus mismeasured (underreported) smoking. The model using mismeasured smoking underestimates the true effect, showing how systematic error in recording an exposure can bias causal estimates toward zero. n &lt;- 2000 age &lt;- rnorm(n, mean = 50, sd = 10) true_smoking &lt;- 2 * age + rnorm(n) # no age to isolate measurement bias in smoking lung_cancer &lt;- 3 * true_smoking + rnorm(n) measured_smoking &lt;- true_smoking - rnorm(n, mean = 1, sd = 0.5) true_model &lt;- lm(lung_cancer ~ true_smoking + age) biased_model &lt;- lm(lung_cancer ~ measured_smoking + age) true_coef &lt;- summary(true_model)$coefficients[&quot;true_smoking&quot;, &quot;Estimate&quot;] biased_coef &lt;- summary(biased_model)$coefficients[&quot;measured_smoking&quot;, &quot;Estimate&quot;] true_coef ## [1] 2.982501 biased_coef ## [1] 2.356849 7.2 Non-Causal Diagrams Non-causal diagrams represent associations between variables that do not imply direct cause-and-effect relationships. These diagrams are useful for illustrating statistical relationships that arise from shared causes, correlations due to bias, or measurement artifacts. In non-causal diagrams, arrows may still indicate directional influence, but they are used to reflect associations or data-generating processes, not claims about interventions. Unlike causal diagrams, which are designed to identify and estimate the effects of manipulating one variable on another, non-causal diagrams help clarify patterns in the data without asserting that changing one variable will necessarily change another. In the context of our simulation, we can use a non-causal diagram to represent the observed association between age and lung cancer without assuming a direct causal relationship. While age and lung cancer may be strongly correlated — older individuals tend to have higher cancer risk — this relationship does not imply that age causes lung cancer in an interventional sense. Instead, age may be acting as a proxy for other underlying factors like cumulative exposure to smoking or environmental risks. A non-causal diagram helps us visualize this statistical association without attributing it to a direct, manipulable pathway, highlighting that not all observed relationships in data should be interpreted as causal. 7.3 Publication Bias and P-Hacking Publication bias occurs when the likelihood of a study being published depends on the nature or direction of its results — typically favoring studies with statistically significant or “positive” findings. This creates a distorted picture of the evidence in a field, because null or contradictory results are less likely to be seen. P-hacking refers to the practice of manipulating statistical analyses or data collection until a desired (usually statistically significant) result is achieved. This can include selectively reporting outcomes, running many analyses and only publishing those with low p-values, or stopping data collection once a significant result appears. Both practices inflate false-positive rates and undermine the credibility of scientific findings. In the context of the simulation we ran — whether it involves confounding, selection bias, or measurement error — it’s easy to see how p-hacking or publication bias could skew interpretations. For example, imagine rerunning the simulation many times and only reporting the version where the naive model shows a significant effect of smoking on lung cancer (even if the underlying data or causal structure doesn’t support it). Or selectively reporting only the adjusted model that produces a “clean” result while hiding others. These practices can make even a carefully designed simulation appear misleading. The simulation reinforces the idea that statistical significance is not the same as truth, and that transparency in modeling choices and full reporting of results are critical for avoiding biased conclusions. 7.4 Over- and Mis-Interpretation of Statistical Analyses Over-interpretation occurs when researchers draw stronger conclusions from statistical results than the data can justify, while mis-interpretation involves misunderstanding what the results actually mean. A common example is interpreting a statistically significant association as proof of causation, even when the study design or model does not support that claim. Another frequent error is overstating the practical importance of a small effect size or assuming that a non-significant result means “no effect.” These issues are often driven by pressure to produce definitive conclusions, even when the data are limited, noisy, or confounded. Careful interpretation requires understanding the limits of the methods used and being transparent about uncertainty, assumptions, and alternative explanations. In the simulations we’ve conducted — such as estimating the effect of smoking on lung cancer under different types of bias — it’s easy to see how results can be over- or mis-interpreted. For instance, in a model affected by measurement bias or confounding, one might find a statistically significant association between smoking and lung cancer, but incorrectly conclude that the estimated effect size reflects the true causal effect. Alternatively, if the biased model appears significant and the true model does not, someone might misinterpret that as evidence that adjustment “eliminated” the effect, when in fact it corrected for bias. These examples highlight how even simple models can be misunderstood or overstated, and underscore the importance of grounding interpretation in study design, data limitations, and causal reasoning — not just statistical output. "],["from-identification-to-estimation.html", "8 From Identification to Estimation Class materials Textbook reading Supplementary reading Topics covered 8.1 Identification and Estimation 8.2 Estimation of causal effects 8.3 Taxonomy of estimation models", " 8 From Identification to Estimation Class materials Slides: Module 8 Recording: Module 8, Part 1 Recording: Module 8, Part 2 Textbook reading Hernán &amp; Robins, Causal Inference: What If – Chapter 14 Supplementary reading VanderWeele, T. J., &amp; Ding, P. (2017). Sensitivity analysis in observational research: introducing the E-value. Annals of Internal Medicine, 167(4), 268–274.  Case studies on unmeasured confounding and robustness of findings Topics covered Identification versus estimation Estimation of causal effects Taxonomy of estimation models Critical reading exercise: evaluating identification and estimation in a published study 8.1 Identification and Estimation In causal inference, identification refers to the theoretical question of whether a causal effect can be determined from the observed data and the assumptions encoded in the study design or model. It answers the question: “Can we, in principle, express the causal effect of interest as a function of the observed variables?” Identification depends on assumptions such as exchangeability (no unmeasured confounding), positivity, and consistency, and often involves tools like potential outcomes or directed acyclic graphs (DAGs). If a causal effect is not identifiable, no amount of statistical analysis will yield a valid estimate — because the data alone cannot disentangle the causal effect from bias or confounding. Once identification is established, the next step is estimation, which involves applying statistical methods to calculate the size of the effect using real data. Estimation uses techniques like regression, inverse probability weighting, or matching to quantify the identified causal relationship. In our simulations, for example, once we specify that the causal effect of smoking on lung cancer is identifiable by adjusting for age, we use regression to estimate that effect. If we skip the identification step and go straight to estimation without accounting for confounding or bias, our estimates may be precise — but wrong. Together, identification and estimation form the backbone of credible causal analysis: one ensures that we’re asking the right question, and the other that we’re answering it correctly. This simulation illustrates the concepts of identification and estimation by showing that, without adjusting for the confounder (age), the causal effect of smoking on lung cancer cannot be correctly identified. Once the effect is identified through proper adjustment, it can then be accurately estimated using regression. n &lt;- 2000 age &lt;- rnorm(2000, mean = 50, sd = 10) smoking &lt;- 2 * age + rnorm(n) lung_cancer &lt;- 3 * smoking + 4 * age + rnorm(n) df &lt;- data.frame( Age = age, Smoking = smoking, Lung_Cancer = lung_cancer ) model_naive &lt;- lm(lung_cancer ~ smoking, data = df) model_adjusted &lt;- lm(lung_cancer ~ smoking + age, data = df) coef_naive &lt;- summary(model_naive)$coefficients[&quot;smoking&quot;, &quot;Estimate&quot;] coef_adjusted &lt;- summary(model_adjusted)$coefficients[&quot;smoking&quot;, &quot;Estimate&quot;] coef_naive ## [1] 4.989247 coef_adjusted ## [1] 3.015073 This simulation ties directly into the distinction between identification and estimation in causal inference. The true causal relationship between smoking and lung cancer is confounded by age, which affects both variables. Without adjusting for age, the naive model fails to identify the causal effect correctly, leading to a biased estimate. Identification is achieved by recognizing and adjusting for age as a confounder, based on assumptions encoded in the study design or a causal diagram. Once this adjustment is made, we can proceed to estimation—using regression to quantify the causal effect of smoking on lung cancer. This demonstrates that correct identification must precede estimation in order to yield valid and interpretable results. 8.2 Estimation of causal effects Estimation of causal effects refers to the process of using statistical methods to quantify the size and direction of a causal relationship between an exposure and an outcome. Once a causal effect has been identified—meaning that, under certain assumptions, it can be expressed in terms of observed variables—estimation allows us to compute a numerical value for that effect using data. Common estimation techniques include linear regression, inverse probability weighting, and matching. The goal is not just to observe an association, but to measure how much changing the exposure would change the outcome, assuming the identification conditions are satisfied. In the simulation above, we estimate the causal effect of smoking on lung cancer. Because age is a confounder that affects both smoking and lung cancer, the naive model (which includes only smoking) gives a biased estimate. By adjusting for age in the regression model, we account for this confounding and can validly estimate the causal effect of smoking. This demonstrates the key idea of estimation: once we’ve identified the correct adjustment set (in this case, age), we can use statistical modeling to derive an accurate effect size that reflects the true causal relationship. 8.3 Taxonomy of estimation models The taxonomy of estimation models refers to the classification of different statistical approaches used to estimate causal effects based on the structure of the data and the assumptions made. Broadly, estimation models fall into categories such as outcome regression (e.g., linear or logistic regression), exposure modeling (e.g., propensity scores), and doubly robust methods that combine both. These models vary in how they handle confounding, missing data, and complexity of relationships between variables. Choosing the appropriate estimation model depends on the research question, the nature of the confounding, and how well the model’s assumptions align with the underlying causal structure. In the simulation above, we use a basic outcome regression model, which is one type in the taxonomy of estimation models. The naive model includes only the exposure (smoking), while the adjusted model includes both smoking and the confounder (age). This approach assumes that the model correctly specifies the relationship between the variables and that confounding is fully captured by age. Although simple, this kind of model is foundational in causal inference, and it illustrates how estimation can be implemented once the appropriate variables have been identified for adjustment. "],["applications-of-causal-inference-in-public-health-and-medical-research.html", "9 Applications of Causal Inference in Public Health and Medical Research Class materials Textbook reading Supplementary reading Topics covered 9.1 Public health policy evaluation 9.2 Environmental exposure studies 9.3 Health disparities research 9.4 Prevention program evaluation", " 9 Applications of Causal Inference in Public Health and Medical Research Class materials Slides: Module 9 Recording: Module 9, Part 1 Recording: Module 9, Part 2 Textbook reading Hernán &amp; Robins, Causal Inference: What If – Chapter 15 Supplementary reading Sterman, J. D. (2006). Learning from evidence in a complex world. American Journal of Public Health, 96(3), 505–514. Examples of systems-level interventions in public health and policy Topics covered Public health policy evaluation Environmental exposure studies Health disparities research Prevention program evaluation 9.1 Public health policy evaluation n &lt;- 2000 baseline_health &lt;- rnorm(n, mean = 50, sd = 10) policy &lt;- ifelse(baseline_health + rnorm(n, 0, 5) &lt; 52, 1, 0) health_outcome &lt;- 5 * policy + 0.6 * baseline_health + rnorm(n, 0, 5) df &lt;- data.frame( Policy = factor(policy, labels = c(&quot;No Policy&quot;, &quot;Policy&quot;)), Baseline_Health = baseline_health, Health_Outcome = health_outcome ) model_naive &lt;- lm(Health_Outcome ~ Policy, data = df) model_adjusted &lt;- lm(Health_Outcome ~ Policy + Baseline_Health, data = df) summary(model_naive)$coefficients[&quot;PolicyPolicy&quot;, ] ## Estimate Std. Error t value Pr(&gt;|t|) ## -3.712213e+00 2.888163e-01 -1.285320e+01 2.187334e-36 summary(model_adjusted)$coefficients[&quot;PolicyPolicy&quot;, ] ## Estimate Std. Error t value Pr(&gt;|t|) ## 4.996592e+00 3.089999e-01 1.617021e+01 2.296516e-55 library(ggplot2) ggplot(df, aes(x = Policy, y = Health_Outcome, fill = Policy)) + geom_boxplot(alpha = 0.6) + labs(title = &quot;Simulated Impact of Public Health Policy&quot;, x = &quot;Policy Implemented&quot;, y = &quot;Health Outcome After 1 Year&quot;) + theme_minimal() 9.2 Environmental exposure studies Environmental exposure studies investigate how exposure to environmental factors—such as air pollution, contaminated water, radiation, or hazardous chemicals—affects human health. These studies aim to establish causal links between environmental conditions and outcomes like respiratory illness, cancer, or developmental disorders. Because randomizing exposure is often unethical or impractical, these studies typically rely on observational data, making careful adjustment for confounders and sources of bias essential. Tools like causal diagrams, regression models, and sensitivity analyses are often employed to assess whether the observed health effects are truly caused by the environmental exposure. In the policy simulation, the setup closely resembles an environmental exposure study where “policy” could be interpreted as an intervention to reduce environmental harm (e.g., enforcing clean air regulations). The simulation demonstrated how individuals exposed to the policy had lower average health outcomes, not because the policy failed, but because those individuals started with worse baseline health. This reflects a common challenge in environmental health research: exposure is often non-random and associated with other risk factors. Just like in environmental exposure studies, it is crucial to adjust for baseline differences—such as pre-existing health or socioeconomic status—to avoid incorrectly concluding that the exposure (or policy) caused harm. 9.3 Health disparities research Health disparities research focuses on understanding and addressing differences in health outcomes across population groups defined by factors such as race, ethnicity, socioeconomic status, geography, gender, or disability. These disparities often stem from unequal access to care, systemic discrimination, environmental exposures, and social determinants of health. The goal is not only to document these differences but also to identify causal pathways and implement interventions that promote health equity. Causal inference tools are especially valuable in this field because they help distinguish between mere correlations and actual structural inequalities that can be targeted through policy and intervention. The simulation of public health policy can be directly applied to health disparities research by modeling how an intervention affects different subgroups. For instance, if a health policy is implemented in lower-income neighborhoods, those individuals might begin with worse baseline health, as shown by lower health outcomes in the policy group. Without adjusting for these baseline differences, the simulation might misleadingly suggest that the policy worsens outcomes. In reality, this reflects the importance of stratifying or adjusting for social determinants when evaluating interventions aimed at reducing disparities. The simulation thus highlights how easily misleading conclusions can arise if disparities are not properly accounted for in causal analysis. 9.4 Prevention program evaluation Prevention program evaluation involves assessing the effectiveness of initiatives designed to reduce the risk of adverse health outcomes before they occur. These programs might target behaviors (e.g., smoking cessation), environmental risks (e.g., air quality improvement), or access to services (e.g., vaccination campaigns). Evaluators aim to determine whether the program caused measurable changes in outcomes such as disease incidence, risk factor reduction, or health equity. This requires careful consideration of confounding factors, selection bias, and whether the observed differences can be attributed to the intervention itself — making causal inference tools central to prevention research. In our simulation, the public health policy acts like a prevention program aimed at improving long-term health outcomes. By comparing the health trajectories of individuals in the policy versus no-policy groups, we can estimate the effect of the intervention. However, the simulation also reveals a key challenge: even if a program targets at-risk populations, initial disparities (like poorer baseline health) may mask its true benefits unless we adjust for those differences. This mirrors real-world prevention evaluations, where randomized trials or proper covariate adjustment are essential to distinguish actual program impact from background variability. "],["presentation-of-final-projects.html", "10 Presentation of Final Projects Class materials Guidelines 10.1 Final Project", " 10 Presentation of Final Projects Class materials Slides: Final Project Overview Recording: Project Presentation Session Guidelines Presentation of Final Projects Review of group projects 10.1 Final Project The final project is a group-based assignment designed to assess your ability to critically evaluate causal claims in real-world public health or epidemiological research. Working in teams of 3–4, you will select a published study and analyze it through the lens of causal inference. This includes clearly identifying the causal question the authors are attempting to answer, articulating the assumptions underlying their analysis, and evaluating whether the study’s design supports a valid causal interpretation. You’ll be expected to consider the use of tools like directed acyclic graphs (DAGs), potential confounders, selection bias, and whether the identification strategy is sound. In addition to identifying strengths and weaknesses in the study, your team will propose potential improvements or alternative approaches that could enhance causal validity. This might involve suggesting better adjustment strategies, different data collection designs, or more transparent modeling techniques. Ultimately, your goal is to interpret the study’s findings not just statistically, but causally — and explain their relevance for real-world public health policy or interventions. Your work will culminate in a 10-minute group presentation during Week 10 and a 3–4 page written report submitted during finals week, both of which demonstrate your ability to apply course concepts to actual scientific literature. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
