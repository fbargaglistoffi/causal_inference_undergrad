# Randomized Control Trials  

> ## Class materials  
>
> Slides: [**Module 2**](https://drive.google.com/file/d/1lseBc7nuJOFFTBKwjDdK7OLf0CLr3_10/view)  
>
> Recording: [**Module 2, Part 1**](https://your-recording-link.com)  
>
> Recording: [**Module 2, Part 2**](https://your-recording-link.com)  

> ## Textbook reading  
>
> [**Hernán & Robins, Causal Inference: What If – Chapters 2*](https://static1.squarespace.com/static/675db8b0dd37046447128f5f/t/677676888e31cc50c2c33877/1735816881944/hernanrobins_WhatIf_2jan25.pdf)  

> ## Supplementary reading  
>
> [**Pearl, J. (2009). Causal inference in statistics: An overview.   Statistics Surveys, 3, 96–146.**](https://projecteuclid.org/journals/statistics-surveys/volume-3/issue-none/Causal-inference-in-statistics-An-overview/10.1214/09-SS057.full)\  
> Selected DAG examples from public health studies (provided in class)  

> ## Topics covered  
>
> -   Randomized controlled trials: the gold standard  
> -   Basic experimental design principles  
> -   Limitations of RCTs in public health contexts  
> -   Common threats to internal and external validity  
> -   Causal Quantities: SATE vs PATE
> -   Critical reading exercise: evaluating a published RCT  

## Randomized controlled trials: the gold standard  

Randomized Controlled Trials (RCTs) are widely considered the gold standard in causal inference because they offer the most rigorous way to establish whether a treatment or intervention truly causes an outcome. The key feature that sets RCTs apart is randomization: participants are randomly assigned to treatment or control groups, which ensures that—on average—all other characteristics (like age, health status, and behaviors) are equally distributed across groups. This process breaks any systematic link between confounders and treatment assignment, making the groups exchangeable and allowing us to interpret differences in outcomes as causal effects of the treatment. 

**Exchangeability** is the key assumption for RCTs, and random assignment of the treatment in RCTs allows us to defend this assumption. Mathematically, exchangeability is written as:  

$$
(Y(1), Y(0)) \perp W
$$
To understand this consider an single person. Exchangeability says that if we have information about what treatment they received, then that doesn't give us any information about what their potential outcome will be. We use exchangeability to identify the average treatment effect (ATE). Identifying the ATE means we are using some assumptions to express the ATE which is expressed in counterfactual outcomes as something that can be expressed using observed data. In this case, the ATE can be written as a difference in means between the treated and control groups.

$$
\begin{align*}
ATE &= E[Y(1) - Y(0)] \\
&= E[Y(1)] - E[Y(0)] \quad \text{by linearity of expectation} \\
&= E[Y(1) \ | \ W=1] - E[Y(0) \ | \  W = 0] \quad \text{by exchangeability} \\
&= E[Y \ | \ W = 1] - E[Y \ | \ W = 0] \quad \text{by consistency}
\end{align*}
$$


Because of this design, RCTs eliminate the need to adjust for confounders or worry about selection bias in the same way observational studies do. They provide clean estimates of the average treatment effect (ATE) with high internal validity, especially when they are well-executed and have minimal loss to follow-up. However, RCTs are not without limitations. They can be expensive, time-consuming, and sometimes unethical or impractical—such as when withholding treatment would cause harm. Despite these limitations, RCTs serve as the benchmark against which other study designs are compared, and understanding their strengths helps us interpret both experimental and non-experimental evidence more critically.  

In this simulation, I will recreate a simple randomized controlled trial (RCT) to estimate the effect of a new treatment on a patient's blood pressure (mmHg). I randomly assigned 2,000 individuals to either a treatment or control group and simulate their outcomes based on their assignment. Because of randomization, I expected the two groups to be similar in baseline characteristics, allowing for an unbiased estimate of the treatment effect. In this example, the baseline characteristics that were measured were age, BMI, cholesterol (mg/dL), and daily sodium intake (mg/day). After simulating the data, I estimated the Average Treatment Effect (ATE) by comparing mean outcomes between the groups, and visualized the distribution of outcomes to confirm the treatment impact.  

**Simulated Baseline Data and Treatment Assignment**  

```{r}

# pacman::p_load("dplyr", "ggplot2")

set.seed(123)

n <- 2000

age <- rnorm(n, 50, 10)

bmi <- rnorm(n, 27, 4)

cholesterol <- rnorm(n, 200, 30)

sodium_intake <- rnorm(n, 3000, 500)

treatment <- rbinom(n, 1, 0.5)

y_0 <- 90 + 0.4 * age + 0.05 * cholesterol + 0.004 * sodium_intake + 
  rnorm(n, sd = 10)

y_1 <- y_0 - 10 + rnorm(n, sd = 5)

y <- ifelse(treatment == 1, y_1, y_0)

rct_data <- data.frame(
  age = age,
  bmi = bmi,
  cholesterol = cholesterol,
  sodium_intake = sodium_intake,
  treatment = treatment,
  y = y
)

head(rct_data)

```

**Estimated the Average Treatment Effect (ATE)**  

```{r}

ate_estimate <- rct_data |>
  group_by(treatment) |>
  summarize(mean_outcome = mean(y)) |>
  summarize(ATE = diff(mean_outcome)) |>
  pull(ATE)

paste("Estimated ATE: ", round(ate_estimate, 2))

```

Based on our estimate, the treatment reduces blood pressure by 10 mmHg.

**Visualization of the Outcome Distributions**  

```{r}

ggplot(rct_data, aes(x = as.factor(treatment), y = y, fill = as.factor(treatment))) + 
  geom_boxplot(alpha = 0.7) + 
  labs(
    title = "Distribution of Outcomes by Treatment Group", 
    x = "Treatment: Control (0) vs Treated (1)",
    y = "Outcome"
  ) + 
  scale_fill_manual(values = c("red", "blue")) +
  theme_minimal()

```


```{r}

# library(cobalt)

bal.out <- bal.tab(treatment~age+bmi+cholesterol+sodium_intake, data = rct_data, s.d.denom = "pooled")

set.cobalt.options(binary = "std")

love.plot(bal.out, limits = c(-0.1, 0.1))

```

This visualization is called a **love plot**. It shows how balanced each of the observed characteristics is between the treated and control group. For example, a value of 0.05 for age means that the treated group's mean age is 0.05 standard deviations above the control group's mean age, which is not much. Typically, an absolute standardized difference value of 0.10 or less typically means that the difference between the groups is negligible. 

So in this plot, all the observed characteristics are balanced. This example shows that random assignment of the treatment balances observed and unobserved characteristics. Since the groups are so similar, we say that the treated and control groups are exchangeable.

## Basic Experimental Design Principles  

At the heart of randomized controlled trials (RCTs) lies experimental design, the set of strategies we use to ensure that the comparison between groups is fair, unbiased, and informative. Good experimental design ensures that any differences in outcomes between the treatment and control groups can be confidently attributed to the treatment itself, and not to other confounding variables. Three basic principles guide experimental design: randomization, control, and replication.  

- Randomization is the process of randomly assigning participants to treatment or control groups. This prevents systematic differences between groups at baseline and ensures that confounding variables (both known and unknown) are evenly distributed.  
- Control involves creating a baseline group (the control group) that does not receive the treatment, allowing for a meaningful comparison.  
- Replication refers to having enough participants so that random fluctuations even out, providing more precise and reliable estimates of the treatment effect.  

In our previous simulation, we applied these principles by randomly assigning 2,000 individuals to either a treatment or control group, simulating outcomes based only on treatment status and baseline characteristics (age). Because we randomized treatment assignment, we can be confident that any observed difference in outcomes is causally attributable to the treatment, not to age differences, baseline health, or other confounders. Without randomization, we would have needed to control for these factors. This simulation highlights why randomization is considered the gold standard for causal inference.  

## Limitations of RCTs in Public Health Contexts  

While randomized controlled trials (RCTs) are the gold standard for establishing causality, they are not without important limitations when applied to public health settings. First, ethical constraints often limit what interventions can be randomly assigned. For example, it would be unethical to randomly assign people to smoke or not smoke in order to study lung cancer. Public health research must often rely on observational studies where randomization is impossible.  

Second, feasibility and cost can be major barriers. Conducting large-scale RCTs can require enormous resources, making them impractical for studying widespread or long-term public health interventions like school nutrition programs or climate effects on health. Generalizability is another concern. Many RCTs are conducted in tightly controlled environments with selective populations, meaning their results may not apply to broader, more diverse real-world populations.  

In our earlier simulation, randomization guaranteed an unbiased estimate of the average treatment effect (ATE) within the study population. However, in real-world public health research, participants who volunteer for RCTs may differ from the general public, and interventions may behave differently outside of controlled settings. This highlights the importance of thinking critically about how experimental results translate into everyday public health practice.  

## Common Threats to Internal and External Validity  

When evaluating any causal study, it's critical to think about validity, whether the results are accurate (internal validity) and whether they generalize beyond the study setting (external validity).  

Internal validity refers to whether the observed effect truly reflects the causal effect within the study population. Threats to internal validity include:  

- Confounding, if randomization fails or is compromised (e.g., noncompliance with assigned treatment).  
- Selection bias, if participants drop out or are lost to follow-up in a way that is related to both treatment and outcome.  
- Measurement error, if outcomes or treatments are recorded inaccurately.  

External validity, on the other hand, concerns whether results from the study can be generalized to other settings, populations, or time periods. Threats to external validity include:  

- Non-representative samples, such as RCTs recruiting only highly motivated individuals who differ from the general population.  
- Intervention differences, where the way a treatment is delivered in a trial setting doesn't match how it would be implemented in the real world.  
- Contextual factors, such as cultural, economic, or healthcare system differences that make the same intervention work differently elsewhere.  

In the earlier RCT simulation, we achieved excellent internal validity because treatment was randomized perfectly and outcomes were cleanly measured. However, that simulation assumes an idealized setting; in real public health research, threats to validity often creep in, and careful design and critical thinking are needed to recognize and minimize them.  

## Causal Quantities: SATE vs PATE

When we do an RCT, we must be careful about the causal quantity of interest we are trying to estimate.

If we are interested in understanding the effect of a treatment for just the individuals in our sample, then we are estimating the **Sample Average Treatment Effect (SATE)**.

$$
\begin{align*}
  SATE = \frac{1}{n}\sum_{i=1}^n (Y_i(1) - Y_i(0))
\end{align*}
$$

Intuitively, the SATE is the average causal effect of individuals in your sample. These results cannot be generalized to a greater population without some assumptions about how sampling was conducted.

If we are trying to understand a causal effect on an entire population beyond just our sample, then we are trying to estimate the **Population Average Treatment Effect (PATE)**. The PATE requires an extra component to the study's design. To estimate the PATE, random sampling must occur to ensure that the sample is representative of the population. This allows us to make conclusions about the population from our sample.

$$
\begin{align*}
PATE &= E[Y(1) - Y(0)]
\end{align*}
$$

The main difference between the SATE and PATE is that the PATE has an extra assumption about randomly sampling from the population. This assumption let's us make conclusions about the causal effect for the entire population, rather than only the sample.

Both estimands can be estimated using the difference in means estimator $\hat{\tau}$:

$$
\begin{align*}
\hat{\tau} &= \frac{1}{n_1} \sum_{i=1}^{n} W_iY_i - \frac{1}{n_0} \sum_{i = 1}^{n}(1-W_i)Y_i
\end{align*}
$$
Since the difference in means estimator is used to estimate both estimands, we have to be extremely careful in specifying whether we are trying to estimate the SATE or PATE.
